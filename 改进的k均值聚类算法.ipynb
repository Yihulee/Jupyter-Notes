{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面使用了k均值聚类来进行测试,虽然说效果貌似还行,但是总觉得不是这样的,我查看过分类出来的group的成员的数据,发现它们其实相关性不大,其实仔细想一想,也对,前面的算法主要是使用pearson距离或者欧几里德距离来度量两个向量的相似度,这样的话,分类出来的数据自然是彼此之间的pearson距离或者欧几里德距离最小的,为了使得我们分类出来的数据满足我们的要求,我们要改动一下相似度计算函数:\n",
    "\n",
    "两组向量相似的话,那么它们每天应该有差不多的运动时间,差不多的静止时间,甚至于每天运动的时段都有所相似,根据这些点,我们可以调整一些参数,控制相似度:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "def conn_db(server=\"127.0.0.1\", user=\"sa\", pwd=\"123\", db=\"moveState\"):\n",
    "    \"\"\"用于连接数据库\"\"\"\n",
    "    return pymssql.connect(server, user, pwd, db)\n",
    "\n",
    "def similarity(v1, v2):\n",
    "    '''\n",
    "    用于计算两个向量的相似度,这个相似度大致是这样来计算的,3月一共有31天,1天有24个小时,\n",
    "    如果在同一天里每个小时的运动状态一致的数目越大,那么相似度越高,一天的权值是1/31,可以通过这种方法\n",
    "    来衡量两辆车运动状态的相似度\n",
    "    '''\n",
    "    def simi_day(d1, d2):\n",
    "        counter = 0\n",
    "        for i in range(24):\n",
    "            if d1[i] == d2[i]:\n",
    "                counter += 1\n",
    "        return counter / 24.0\n",
    "\n",
    "    def simi_day_ex(d1, d2):\n",
    "        '''\n",
    "        用另外一种评价标准,因为不运动的时间占据了车辆的绝大多数时间,所以即使相似度不大的两种车\n",
    "        因为这个缘故用上面的评价标准的话,也会变得很相似,所以要改进相似度的评价\n",
    "       '''\n",
    "        simi_t = 0.0 # 一天中同处在运动状态的小时的计数\n",
    "        diff_t = 0.0 # 一天内两车处于不相同的运动状态的小时的次数\n",
    "        # 都处在静止状态就排除掉了\n",
    "        for i in range(24):\n",
    "            if d1[i] == d2[i] == 1:\n",
    "                simi_t += 1\n",
    "            elif d1[i] != d2[i]:\n",
    "                diff_t += 1\n",
    "        divisor = simi_t + diff_t\n",
    "        if  divisor == 0:\n",
    "            return 0.25\n",
    "        else:\n",
    "            return (simi_t / divisor) * 0.75 + ((24 - divisor) / 24) * 0.25\n",
    "\n",
    "    simi = 0.0\n",
    "    for day in range(31):\n",
    "        start = day * 24\n",
    "        end = start + 24\n",
    "        simi += simi_day_ex(v1[start:end], v2[start:end])\n",
    "    return simi\n",
    "\n",
    "def kcluster(rows, distance=similarity, k=10):\n",
    "    \"\"\"k均值聚类\"\"\"\n",
    "    # 随机创建k个中心点\n",
    "    # random.random()返回一个在[0.0, 1.0)之间的伪随机数\n",
    "    def rand():\n",
    "        if random.random() >= 0.5:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    n = len(rows[0]) # 向量的长度\n",
    "    clusters = [[rand() for i in range(n)] for j in range(k)]\n",
    "\n",
    "    lastmatches = None\n",
    "    for t in range(25): # 最多迭代100次\n",
    "        print('Iteration %d' % t)\n",
    "        bestmatches = [[] for i in range(k)]\n",
    "        # 在每一行中寻找距离最近的中心点\n",
    "        for j in range(len(rows)):\n",
    "            row = rows[j]\n",
    "            bestmatch = 0\n",
    "            for i in range(k):\n",
    "                d = distance(clusters[i], row)\n",
    "                if d < distance(clusters[bestmatch], row): bestmatch = i\n",
    "            bestmatches[bestmatch].append(j) # 将行的行号加入\n",
    "        # 如果结果与上一次相同,则整个过程结束\n",
    "        if bestmatches == lastmatches: break\n",
    "        lastmatches = bestmatches\n",
    "\n",
    "        # 将中心点移到其所有成员的平均位置\n",
    "        for i in range(k):\n",
    "            avgs = [0.0] * n\n",
    "            if len(bestmatches[i]) > 0:\n",
    "                for rowid in bestmatches[i]:\n",
    "                    for m in range(n): #\n",
    "                        avgs[m] += rows[rowid][m] # 将rows[rowid]对应位置的\n",
    "\n",
    "                for j in range(n): # 其实就是求一下平均值\n",
    "                    avgs[j] /= len(bestmatches[i])\n",
    "                    if avgs[j] >= 0.35:\n",
    "                        avgs[j] = 1\n",
    "                    else:\n",
    "                        avgs[j] = 0\n",
    "                clusters[i] = avgs\n",
    "    return bestmatches\n",
    "\n",
    "# 接下来要使用迭代器获得数据\n",
    "def get_next_vec(conn):\n",
    "    \"\"\"获得数据向量\"\"\"\n",
    "    def clean_data(item):\n",
    "        if item == None:\n",
    "            return 0\n",
    "        else:\n",
    "            return item\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"select * from MoveState03\")\n",
    "    row = cursor.fetchone()\n",
    "    while row:\n",
    "        # 在这里,我们要对数据进行一定程度的清理,具体是将NULL变为0\n",
    "        yield (row[0], list(map(clean_data, row[1:])))\n",
    "        row = cursor.fetchone()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conn = conn_db()\n",
    "    count = 0\n",
    "    rows = {}\n",
    "    # 获取20辆车的数据\n",
    "    size = 380\n",
    "    for item in get_next_vec(conn):\n",
    "        id, vec = item\n",
    "        rows[id] = vec\n",
    "        #print(vec)\n",
    "        count = count + 1\n",
    "        if count >= size: break\n",
    "    r = [v for x, v in rows.items()]\n",
    "    print(\"100 car's data got!\")\n",
    "    bestmatch = kcluster(r)\n",
    "    i = 1\n",
    "    with open(\"res.txt\", mode='w') as f:\n",
    "        for group in bestmatch:\n",
    "            print(\"group %02d: %s\" %(i, group))\n",
    "            f.write(\"group %02d:\\n\" % i)\n",
    "            for index in group:\n",
    "                f.write(\"%04d -> %s\\n\" %(index, r[index]))\n",
    "            i = i + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关系数的调整花费了我挺长的一段时间,刚开始的时候,一大堆的数据总是收敛到一个类里面,但是经过微微调整之后,效果有所提升,然后查看生成的txt文件,发现分类基本满足了要求,从稀疏度,具体的活动时间等指标可以看出来."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
